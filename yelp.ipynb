{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists.\n",
      "Folder already exists.\n"
     ]
    }
   ],
   "source": [
    "# DEFAULTS\n",
    "\n",
    "# define folder structure\n",
    "base_path = os.getcwd()\n",
    "data_path = base_path + '/data'\n",
    "intermediate_data_path = data_path + '/intermediate'\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(intermediate_data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MODELS\n",
    "\n",
    "# Business\n",
    "class Business:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "businesses = dict()\n",
    "\n",
    "# Checkin\n",
    "class Checkin:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "checkins = []\n",
    "\n",
    "# Review\n",
    "class Review:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "reviews = dict()\n",
    "\n",
    "# Tip\n",
    "class Tip:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "tips = []\n",
    "\n",
    "# User\n",
    "class User:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "users = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 192609/192609 [00:02<00:00, 68128.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 161950/161950 [00:01<00:00, 127319.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3527653ceaa8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/yelp/yelp_academic_dataset_review.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mreviews_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreviews_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mreviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;31m# decode input (taking the buffer into account)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import files\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_business.json', encoding=\"utf8\") as businesses_file:\n",
    "    for l in tqdm(businesses_file.readlines()):\n",
    "        b = Business(json.loads(l))\n",
    "        businesses[b.business_id] = b\n",
    "\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_checkin.json', encoding=\"utf8\") as checkins_file:\n",
    "    for l in tqdm(checkins_file.readlines()):\n",
    "        c = Checkin(json.loads(l))\n",
    "        checkins.append(c)\n",
    "\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_review.json', encoding=\"utf8\") as reviews_file:\n",
    "    for l in tqdm(reviews_file.readlines()):\n",
    "        r = Review(json.loads(l))\n",
    "        reviews[r.review_id] = r\n",
    "\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_tip.json', encoding=\"utf8\") as tips_file:\n",
    "    for l in tqdm(tips_file.readlines()):\n",
    "        t = Tip(json.loads(l))\n",
    "        tips.append(t)\n",
    "\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_user.json', encoding=\"utf8\") as users_file:\n",
    "    for l in tqdm(users_file.readlines()):\n",
    "        u = User(json.loads(l))\n",
    "        users[u.user_id] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of Businesses: \" + str(len(businesses)))\n",
    "print(\"# of Checkins: \" + str(len(checkins)))\n",
    "print(\"# of Reviews: \" + str(len(reviews)))\n",
    "print(\"# of Tips: \" + str(len(tips)))\n",
    "print(\"# of Users: \" + str(len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations:\n",
    "\n",
    "* down hill -\n",
    "* great price +\n",
    "* high quality +\n",
    "* poor quality -\n",
    "* huge fan +\n",
    "\n",
    "## Indicators for negative reviews:\n",
    "* avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zipf_table(WORDS, sort_parameters=(\"rank\", \"ascending\"), num_rows=10):\n",
    "    '''\n",
    "    WORDS = list of words;\n",
    "    sort_parameters is 2 tuple: ((\"rank\" | \"frequency\" | \"frequency_times_rank\"), (\"ascending\" | \"descending\"))\n",
    "    num_rows: number of rows displayed in table\n",
    "\n",
    "    '''\n",
    "    zipf_values = [(wort, frequ, rank, frequ*rank) for rank, (wort, frequ) in enumerate(Counter(WORDS).most_common(len(WORDS)), 1)]\n",
    "     \n",
    "    if sort_parameters[0] in (\"rank\", \"frequency\", \"frequency_times_rank\") and sort_parameters[1] in (\"ascending\", \"descending\"):\n",
    "        if sort_parameters[1] == \"ascending\":\n",
    "            sorting_order = False\n",
    "        else:\n",
    "            sorting_order = True\n",
    "        if sort_parameters[0] == \"rank\":\n",
    "            zipf_values.sort(key = lambda values: values[2], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency\":\n",
    "            print(\"ja\")\n",
    "            zipf_values.sort(key = lambda values: values[1], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency_times_rank\":\n",
    "            zipf_values.sort(key = lambda values: values[3], reverse=sorting_order)\n",
    "\n",
    "        print(\"\\n\\nZipf’s law\\n\")\n",
    "        print(\"word\"+12*(\" \")+ \"frequency\" +5*(\" \") + \"rank\"+ 9*(\" \") + \"f*runtitled:Untitled-1\")\n",
    "        print(\"-----------------------------------------------\")   \n",
    "        i = 0\n",
    "        for wort, f, r, f_r in zipf_values:\n",
    "            if i < num_rows:\n",
    "                i += 1 \n",
    "                if len(str(wort))<15:\n",
    "                    wort = wort+ \" \"*(15-len(str(wort)))\n",
    "                if len(str(f))<12:\n",
    "                    f_str = str(f) + \" \"*(12-len(str(f)))\n",
    "                if len(str(r))<12:\n",
    "                    r_str = str(r) + \" \"*(12-len(str(r)))\n",
    "                if len(str(f_r))<12:\n",
    "                    f_r_str = str(f_r)+ \" \"*(12-len(str(f_r)))\n",
    "                print(wort,f_str,r_str,f_r_str, \"\\n\")   \n",
    "            else:\n",
    "                 break\n",
    "    else:\n",
    "        print(\"Invalid sorting parameter(s)!\")\n",
    "    return zipf_values\n",
    "\n",
    "def get_words(review_dict):\n",
    "    #return [word for review_obj in review_dict.values() for word in nltk.word_tokenize(review_obj.text)]\n",
    "    all_words = []\n",
    "    for review_obj in tqdm(review_dict.values()):\n",
    "        for word in nltk.word_tokenize(review_obj.text):\n",
    "            all_words.append(word)\n",
    "    return all_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thounsand_reviews = {key:value for index, (key, value) in enumerate(reviews.items()) if index < 10000}\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORDS = compute_zipf_table(get_words(thounsand_reviews), (\"rank\", \"descending\"), num_rows=100)\n",
    "\n",
    "print(len(WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
