{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have:\n",
    "1. Reviews : a list of reviws of the movies\n",
    "2. Labels: 0 (negative) or 4 (positive), sentiment score for the corresponding review\n",
    "3. Review : Label pairing\n",
    "\n",
    "What we want:\n",
    "1. Review -> Classifier Model -> Predicted Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# splits your X and Y data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# used to represent text via frequencies of its words\n",
    "# can be replace with TfIdfVectorizer, for example\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# use module of logistic regression function (more on that can be found in documentation)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_basepath = './'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring / reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(data_basepath + 'data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = tweet_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first 50k data samples\n",
    "data = tweet_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check proportion of pos / neg examples, should be relatively equal\n",
    "print(data[data['target'] == 0].shape)\n",
    "print(data[data['target'] == 4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "\n",
    "data_records = data.to_dict('records')\n",
    "input_text = [each_item['tweet_proc'] for each_item in data_records]\n",
    "input_labels = [each_item['target'] for each_item in data_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet preprocessing caused some tweets to be empty (e.g., those with punctuation only, for example)\n",
    "# required to remove them\n",
    "\n",
    "nan_indices = []\n",
    "\n",
    "for num, i in enumerate(input_text):\n",
    "    if type(i) is not str:\n",
    "        nan_indices.append(num)\n",
    "        \n",
    "new_input_text = [item for num, item in enumerate(input_text) if num not in nan_indices]\n",
    "\n",
    "new_input_labels = [item for num, item in enumerate(input_labels) if num not in nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "# specity train size (normally 80% of all data)\n",
    "# specify random state, so that next time one runs this notebook, images are splitted into the same sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                new_input_text,\n",
    "                new_input_labels,\n",
    "                train_size=0.90,\n",
    "                random_state=1875754\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represent input texts as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# train representation\n",
    "X_train_countvec = count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# test representation\n",
    "X_test_countvec = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_countvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features are represented by all unique words which are found in the tweets\n",
    "count_vectorizer.get_feature_names()[4000:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model object and fit data to this object\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model = logistic_model.fit(X=X_train_countvec, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict sentiment based on document-term matrix of X_test\n",
    "y_pred = logistic_model.predict(X_test_countvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.score(X=X_test_countvec, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct resulting dataframe\n",
    "output_df = pd.DataFrame(columns=['tweet', 'actual', 'predicted'])\n",
    "for i in range(len(X_test)):\n",
    "    output_df.loc[i] = [X_test[i], y_test[i], y_pred[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, row in output_df.iterrows():\n",
    "    print('TWEET', row['tweet'])\n",
    "    print('SENTIMENT', row['predicted'])\n",
    "    print('REAL SENTIMENT', row['actual'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
