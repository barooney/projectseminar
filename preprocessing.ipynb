{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import reverse_geocoder\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Folder already exists.\nFolder already exists.\n"
    }
   ],
   "source": [
    "# DEFAULTS\n",
    "\n",
    "# define folder structure\n",
    "base_path = os.getcwd()\n",
    "data_path = base_path + '/data'\n",
    "intermediate_data_path = data_path + '/intermediate'\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(intermediate_data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MODELS\n",
    "\n",
    "# Business\n",
    "class Business:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "businesses = dict()\n",
    "\n",
    "# Review\n",
    "class Review:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "reviews = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 192609/192609 [00:04<00:00, 47892.39it/s]# of Businesses: 192609\n\n"
    }
   ],
   "source": [
    "# import businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_business.json', encoding=\"utf8\") as businesses_file:\n",
    "    for l in tqdm(businesses_file.readlines()):\n",
    "        b = Business(json.loads(l))\n",
    "        businesses[b.business_id] = b\n",
    "\n",
    "print(\"# of Businesses: \" + str(len(businesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading formatted geocoded file...\nIllinois: 1930\n"
    }
   ],
   "source": [
    "# Filter businesses by state.\n",
    "\n",
    "# Choose the state(s) to filter\n",
    "STATE_TO_FILTER = 'Illinois'\n",
    "\n",
    "states = dict()\n",
    "def add_or_update(state, business):\n",
    "    if state in states:\n",
    "        states[state].add(business)\n",
    "    else:\n",
    "        states[state] = set([business])\n",
    "\n",
    "business_list = list(businesses.values())\n",
    "\n",
    "# Find coordinates by using the reverse_geocoder\n",
    "coordinates = [(c.latitude, c.longitude) for c in business_list]\n",
    "res = reverse_geocoder.search(coordinates)\n",
    "ctr = 0\n",
    "for r in res:\n",
    "    state = r['admin1']\n",
    "    if state == STATE_TO_FILTER:\n",
    "        add_or_update(state, business_list[ctr])\n",
    "    ctr += 1\n",
    "\n",
    "for s in states:\n",
    "    print(s + \": \" + str(len(states[s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# Businesses to be reviewed: 1930\n100%|██████████| 6685900/6685900 [01:01<00:00, 108530.29it/s]\n# Reviews loaded: 42316\n"
    }
   ],
   "source": [
    "# List all businesses of the given states\n",
    "business_ids = set()\n",
    "for b in states[STATE_TO_FILTER]:\n",
    "    business_ids.add(b.business_id)\n",
    "\n",
    "# Get the number of businesses to look for reviews for\n",
    "print(\"# Businesses to be reviewed: \" + str(len(business_ids)))\n",
    "\n",
    "# Load all reviews with respect to the given businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_review.json', encoding=\"utf8\") as reviews_file:\n",
    "    for l in tqdm(reviews_file.readlines()):\n",
    "        r = Review(json.loads(l))\n",
    "        if r.business_id in business_ids:\n",
    "            reviews[r.review_id] = r\n",
    "\n",
    "print(\"# Reviews loaded: \" + str(len(reviews.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_businesses.json', 'w')\n",
    "for b in businesses:\n",
    "    json.dump(businesses[b].__dict__, businesses_intermediate_file)\n",
    "    businesses_intermediate_file.write(\"\\n\")\n",
    "businesses_intermediate_file.close()\n",
    "\n",
    "reviews_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_reviews.json', 'w')\n",
    "for r in reviews:\n",
    "    json.dump(reviews[r].__dict__, reviews_intermediate_file)\n",
    "    reviews_intermediate_file.write(\"\\n\")\n",
    "reviews_intermediate_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations:\n",
    "\n",
    "* down hill -\n",
    "* great price +\n",
    "* high quality +\n",
    "* poor quality -\n",
    "* huge fan +\n",
    "\n",
    "## Indicators for negative reviews:\n",
    "* avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zipf_table(WORDS, sort_parameters=(\"rank\", \"ascending\"), num_rows=10):\n",
    "    '''\n",
    "    WORDS = list of words;\n",
    "    sort_parameters is 2 tuple: ((\"rank\" | \"frequency\" | \"frequency_times_rank\"), (\"ascending\" | \"descending\"))\n",
    "    num_rows: number of rows displayed in table\n",
    "\n",
    "    '''\n",
    "    zipf_values = [(wort, frequ, rank, frequ*rank) for rank, (wort, frequ) in enumerate(Counter(WORDS).most_common(len(WORDS)), 1)]\n",
    "     \n",
    "    if sort_parameters[0] in (\"rank\", \"frequency\", \"frequency_times_rank\") and sort_parameters[1] in (\"ascending\", \"descending\"):\n",
    "        if sort_parameters[1] == \"ascending\":\n",
    "            sorting_order = False\n",
    "        else:\n",
    "            sorting_order = True\n",
    "        if sort_parameters[0] == \"rank\":\n",
    "            zipf_values.sort(key = lambda values: values[2], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency\":\n",
    "            print(\"ja\")\n",
    "            zipf_values.sort(key = lambda values: values[1], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency_times_rank\":\n",
    "            zipf_values.sort(key = lambda values: values[3], reverse=sorting_order)\n",
    "\n",
    "        print(\"\\n\\nZipf’s law\\n\")\n",
    "        print(\"word\"+12*(\" \")+ \"frequency\" +5*(\" \") + \"rank\"+ 9*(\" \") + \"f*runtitled:Untitled-1\")\n",
    "        print(\"-----------------------------------------------\")   \n",
    "        i = 0\n",
    "        for wort, f, r, f_r in zipf_values:\n",
    "            if i < num_rows:\n",
    "                i += 1 \n",
    "                if len(str(wort))<15:\n",
    "                    wort = wort+ \" \"*(15-len(str(wort)))\n",
    "                if len(str(f))<12:\n",
    "                    f_str = str(f) + \" \"*(12-len(str(f)))\n",
    "                if len(str(r))<12:\n",
    "                    r_str = str(r) + \" \"*(12-len(str(r)))\n",
    "                if len(str(f_r))<12:\n",
    "                    f_r_str = str(f_r)+ \" \"*(12-len(str(f_r)))\n",
    "                print(wort,f_str,r_str,f_r_str, \"\\n\")   \n",
    "            else:\n",
    "                 break\n",
    "    else:\n",
    "        print(\"Invalid sorting parameter(s)!\")\n",
    "    return zipf_values\n",
    "\n",
    "def get_words(review_dict):\n",
    "    #return [word for review_obj in review_dict.values() for word in nltk.word_tokenize(review_obj.text)]\n",
    "    all_words = []\n",
    "    for review_obj in tqdm(review_dict.values()):\n",
    "        for word in nltk.word_tokenize(review_obj.text):\n",
    "            all_words.append(word)\n",
    "    return all_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thounsand_reviews = {key:value for index, (key, value) in enumerate(reviews.items()) if index < 10000}\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 10000/10000 [00:10<00:00, 974.01it/s]\n\n\nZipf’s law\n\nword            frequency     rank         f*runtitled:Untitled-1\n-----------------------------------------------\n.trust          1            34123        34123        \n\nshift/slide     1            34122        34122        \n\ntectonic        1            34121        34121        \n\n'in-between     1            34120        34120        \n\nhardness/thickness/denseness 1            34119        34119        \n\nit.m            1            34118        34118        \n\nENOUGH          1            34117        34117        \n\nchalkenge       1            34116        34116        \n\nhockey-puck     1            34115        34115        \n\n3300            1            34114        34114        \n\nMedicare        1            34113        34113        \n\n.charge         1            34112        34112        \n\nGarfield        1            34111        34111        \n\nVaries          1            34110        34110        \n\nmust-see-stop   1            34109        34109        \n\nspoiler         1            34108        34108        \n\nmayo..ca        1            34107        34107        \n\nThree-cup       1            34106        34106        \n\nthree-cup       1            34105        34105        \n\ndutifully       1            34104        34104        \n\nsecs            1            34103        34103        \n\nherewithin      1            34102        34102        \n\nhippa           1            34101        34101        \n\nFamila          1            34100        34100        \n\n75.             1            34099        34099        \n\nbrunch/lunch    1            34098        34098        \n\nSTEAKS          1            34097        34097        \n\nPANCAKES        1            34096        34096        \n\nViolet          1            34095        34095        \n\nprciey          1            34094        34094        \n\nZelma           1            34093        34093        \n\ntea..there      1            34092        34092        \n\nrallying        1            34091        34091        \n\nWall            1            34090        34090        \n\nTitan           1            34089        34089        \n\nMALES           1            34088        34088        \n\nmales           1            34087        34087        \n\nprofessed       1            34086        34086        \n\nstAre           1            34085        34085        \n\nnerdy           1            34084        34084        \n\nlifetimes       1            34083        34083        \n\nBatiks          1            34082        34082        \n\nhedgehogs       1            34081        34081        \n\nBabar           1            34080        34080        \n\nSteel           1            34079        34079        \n\nCotton          1            34078        34078        \n\nahhhs           1            34077        34077        \n\nmilkshake..     1            34076        34076        \n\nann             1            34075        34075        \n\nSC              1            34074        34074        \n\nlick            1            34073        34073        \n\nroommmate       1            34072        34072        \n\nditto           1            34071        34071        \n\nbait            1            34070        34070        \n\nFrance          1            34069        34069        \n\nBrittany        1            34068        34068        \n\nbaseline        1            34067        34067        \n\nlicence         1            34066        34066        \n\nused-car        1            34065        34065        \n\nmandate         1            34064        34064        \n\nnearly-empty    1            34063        34063        \n\n14k             1            34062        34062        \n\npractically-new 1            34061        34061        \n\n30-point        1            34060        34060        \n\ndynamics        1            34059        34059        \n\nYakisoba        1            34058        34058        \n\ncomplying       1            34057        34057        \n\nsusan           1            34056        34056        \n\ntaiwanese/chinese 1            34055        34055        \n\nstein           1            34054        34054        \n\nf*ed            1            34053        34053        \n\n12/8/15         1            34052        34052        \n\n119             1            34051        34051        \n\nXrays           1            34050        34050        \n\nrestated        1            34049        34049        \n\njug             1            34048        34048        \n\nchildlike       1            34047        34047        \n\nhighways        1            34046        34046        \n\ndenotes         1            34045        34045        \n\nreason..        1            34044        34044        \n\nclipboards      1            34043        34043        \n\nclassified      1            34042        34042        \n\nimplicit        1            34041        34041        \n\nnotarize        1            34040        34040        \n\nnotarized       1            34039        34039        \n\nrelating        1            34038        34038        \n\nbar/grabbing    1            34037        34037        \n\nlinked          1            34036        34036        \n\nBf              1            34035        34035        \n\nsizes/weights   1            34034        34034        \n\nbowlers         1            34033        34033        \n\nALLEY           1            34032        34032        \n\nBOWLING         1            34031        34031        \n\ncmon            1            34030        34030        \n\nfixated         1            34029        34029        \n\n.WOW            1            34028        34028        \n\nstaff/management 1            34027        34027        \n\nJesse           1            34026        34026        \n\nsemi-upscale    1            34025        34025        \n\npiccolo         1            34024        34024        \n\n34123\n"
    }
   ],
   "source": [
    "\n",
    "WORDS = compute_zipf_table(get_words(thounsand_reviews), (\"rank\", \"descending\"), num_rows=100)\n",
    "\n",
    "print(len(WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}