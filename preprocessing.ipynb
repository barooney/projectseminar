{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import reverse_geocoder\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists.\n",
      "Folder already exists.\n"
     ]
    }
   ],
   "source": [
    "# DEFAULTS\n",
    "\n",
    "# define folder structure\n",
    "base_path = os.getcwd()\n",
    "data_path = base_path + '/data'\n",
    "intermediate_data_path = data_path + '/intermediate'\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(intermediate_data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MODELS\n",
    "\n",
    "# Business\n",
    "class Business:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "businesses = dict()\n",
    "\n",
    "# Review\n",
    "class Review:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "reviews = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:04<00:00, 47892.39it/s]# of Businesses: 192609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_business.json', encoding=\"utf8\") as businesses_file:\n",
    "    for l in tqdm(businesses_file.readlines()):\n",
    "        b = Business(json.loads(l))\n",
    "        businesses[b.business_id] = b\n",
    "\n",
    "print(\"# of Businesses: \" + str(len(businesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "Illinois: 1930\n"
     ]
    }
   ],
   "source": [
    "# Filter businesses by state.\n",
    "\n",
    "# Choose the state(s) to filter\n",
    "STATE_TO_FILTER = 'Illinois'\n",
    "\n",
    "states = dict()\n",
    "def add_or_update(state, business):\n",
    "    if state in states:\n",
    "        states[state].add(business)\n",
    "    else:\n",
    "        states[state] = set([business])\n",
    "\n",
    "business_list = list(businesses.values())\n",
    "\n",
    "# Find coordinates by using the reverse_geocoder\n",
    "coordinates = [(c.latitude, c.longitude) for c in business_list]\n",
    "res = reverse_geocoder.search(coordinates)\n",
    "ctr = 0\n",
    "for r in res:\n",
    "    state = r['admin1']\n",
    "    if state == STATE_TO_FILTER:\n",
    "        add_or_update(state, business_list[ctr])\n",
    "    ctr += 1\n",
    "\n",
    "for s in states:\n",
    "    print(s + \": \" + str(len(states[s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Businesses to be reviewed: 1930\n",
      "100%|██████████| 6685900/6685900 [01:01<00:00, 108530.29it/s]\n",
      "# Reviews loaded: 42316\n"
     ]
    }
   ],
   "source": [
    "# List all businesses of the given states\n",
    "business_ids = set()\n",
    "for b in states[STATE_TO_FILTER]:\n",
    "    business_ids.add(b.business_id)\n",
    "\n",
    "# Get the number of businesses to look for reviews for\n",
    "print(\"# Businesses to be reviewed: \" + str(len(business_ids)))\n",
    "\n",
    "# Load all reviews with respect to the given businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_review.json', encoding=\"utf8\") as reviews_file:\n",
    "    for l in tqdm(reviews_file.readlines()):\n",
    "        r = Review(json.loads(l))\n",
    "        if r.business_id in business_ids:\n",
    "            reviews[r.review_id] = r\n",
    "\n",
    "print(\"# Reviews loaded: \" + str(len(reviews.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_businesses.json', 'w')\n",
    "for b in businesses:\n",
    "    json.dump(businesses[b].__dict__, businesses_intermediate_file)\n",
    "    businesses_intermediate_file.write(\"\\n\")\n",
    "businesses_intermediate_file.close()\n",
    "\n",
    "reviews_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_reviews.json', 'w')\n",
    "for r in reviews:\n",
    "    json.dump(reviews[r].__dict__, reviews_intermediate_file)\n",
    "    reviews_intermediate_file.write(\"\\n\")\n",
    "reviews_intermediate_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations:\n",
    "\n",
    "* down hill -\n",
    "* great price +\n",
    "* high quality +\n",
    "* poor quality -\n",
    "* huge fan +\n",
    "\n",
    "## Indicators for negative reviews:\n",
    "* avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zipf_table(WORDS, sort_parameters=(\"rank\", \"ascending\"), num_rows=10):\n",
    "    '''\n",
    "    WORDS = list of words;\n",
    "    sort_parameters is 2 tuple: ((\"rank\" | \"frequency\" | \"frequency_times_rank\"), (\"ascending\" | \"descending\"))\n",
    "    num_rows: number of rows displayed in table\n",
    "\n",
    "    '''\n",
    "    zipf_values = [(wort, frequ, rank, frequ*rank) for rank, (wort, frequ) in enumerate(Counter(WORDS).most_common(len(WORDS)), 1)]\n",
    "     \n",
    "    if sort_parameters[0] in (\"rank\", \"frequency\", \"frequency_times_rank\") and sort_parameters[1] in (\"ascending\", \"descending\"):\n",
    "        if sort_parameters[1] == \"ascending\":\n",
    "            sorting_order = False\n",
    "        else:\n",
    "            sorting_order = True\n",
    "        if sort_parameters[0] == \"rank\":\n",
    "            zipf_values.sort(key = lambda values: values[2], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency\":\n",
    "            print(\"ja\")\n",
    "            zipf_values.sort(key = lambda values: values[1], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency_times_rank\":\n",
    "            zipf_values.sort(key = lambda values: values[3], reverse=sorting_order)\n",
    "\n",
    "        print(\"\\n\\nZipf’s law\\n\")\n",
    "        print(\"word\"+12*(\" \")+ \"frequency\" +5*(\" \") + \"rank\"+ 9*(\" \") + \"f*runtitled:Untitled-1\")\n",
    "        print(\"-----------------------------------------------\")   \n",
    "        i = 0\n",
    "        for wort, f, r, f_r in zipf_values:\n",
    "            if i < num_rows:\n",
    "                i += 1 \n",
    "                if len(str(wort))<15:\n",
    "                    wort = wort+ \" \"*(15-len(str(wort)))\n",
    "                if len(str(f))<12:\n",
    "                    f_str = str(f) + \" \"*(12-len(str(f)))\n",
    "                if len(str(r))<12:\n",
    "                    r_str = str(r) + \" \"*(12-len(str(r)))\n",
    "                if len(str(f_r))<12:\n",
    "                    f_r_str = str(f_r)+ \" \"*(12-len(str(f_r)))\n",
    "                print(wort,f_str,r_str,f_r_str, \"\\n\")   \n",
    "            else:\n",
    "                 break\n",
    "    else:\n",
    "        print(\"Invalid sorting parameter(s)!\")\n",
    "    return zipf_values\n",
    "\n",
    "def get_words(review_dict):\n",
    "    #return [word for review_obj in review_dict.values() for word in nltk.word_tokenize(review_obj.text)]\n",
    "    all_words = []\n",
    "    for review_obj in tqdm(review_dict.values()):\n",
    "        for word in nltk.word_tokenize(review_obj.text):\n",
    "            all_words.append(word)\n",
    "    return all_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thounsand_reviews = {key:value for index, (key, value) in enumerate(reviews.items()) if index < 10000}\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 974.01it/s]\n",
      "\n",
      "\n",
      "Zipf’s law\n",
      "\n",
      "word            frequency     rank         f*runtitled:Untitled-1\n",
      "-----------------------------------------------\n",
      ".trust          1            34123        34123        \n",
      "\n",
      "shift/slide     1            34122        34122        \n",
      "\n",
      "tectonic        1            34121        34121        \n",
      "\n",
      "'in-between     1            34120        34120        \n",
      "\n",
      "hardness/thickness/denseness 1            34119        34119        \n",
      "\n",
      "it.m            1            34118        34118        \n",
      "\n",
      "ENOUGH          1            34117        34117        \n",
      "\n",
      "chalkenge       1            34116        34116        \n",
      "\n",
      "hockey-puck     1            34115        34115        \n",
      "\n",
      "3300            1            34114        34114        \n",
      "\n",
      "Medicare        1            34113        34113        \n",
      "\n",
      ".charge         1            34112        34112        \n",
      "\n",
      "Garfield        1            34111        34111        \n",
      "\n",
      "Varies          1            34110        34110        \n",
      "\n",
      "must-see-stop   1            34109        34109        \n",
      "\n",
      "spoiler         1            34108        34108        \n",
      "\n",
      "mayo..ca        1            34107        34107        \n",
      "\n",
      "Three-cup       1            34106        34106        \n",
      "\n",
      "three-cup       1            34105        34105        \n",
      "\n",
      "dutifully       1            34104        34104        \n",
      "\n",
      "secs            1            34103        34103        \n",
      "\n",
      "herewithin      1            34102        34102        \n",
      "\n",
      "hippa           1            34101        34101        \n",
      "\n",
      "Famila          1            34100        34100        \n",
      "\n",
      "75.             1            34099        34099        \n",
      "\n",
      "brunch/lunch    1            34098        34098        \n",
      "\n",
      "STEAKS          1            34097        34097        \n",
      "\n",
      "PANCAKES        1            34096        34096        \n",
      "\n",
      "Violet          1            34095        34095        \n",
      "\n",
      "prciey          1            34094        34094        \n",
      "\n",
      "Zelma           1            34093        34093        \n",
      "\n",
      "tea..there      1            34092        34092        \n",
      "\n",
      "rallying        1            34091        34091        \n",
      "\n",
      "Wall            1            34090        34090        \n",
      "\n",
      "Titan           1            34089        34089        \n",
      "\n",
      "MALES           1            34088        34088        \n",
      "\n",
      "males           1            34087        34087        \n",
      "\n",
      "professed       1            34086        34086        \n",
      "\n",
      "stAre           1            34085        34085        \n",
      "\n",
      "nerdy           1            34084        34084        \n",
      "\n",
      "lifetimes       1            34083        34083        \n",
      "\n",
      "Batiks          1            34082        34082        \n",
      "\n",
      "hedgehogs       1            34081        34081        \n",
      "\n",
      "Babar           1            34080        34080        \n",
      "\n",
      "Steel           1            34079        34079        \n",
      "\n",
      "Cotton          1            34078        34078        \n",
      "\n",
      "ahhhs           1            34077        34077        \n",
      "\n",
      "milkshake..     1            34076        34076        \n",
      "\n",
      "ann             1            34075        34075        \n",
      "\n",
      "SC              1            34074        34074        \n",
      "\n",
      "lick            1            34073        34073        \n",
      "\n",
      "roommmate       1            34072        34072        \n",
      "\n",
      "ditto           1            34071        34071        \n",
      "\n",
      "bait            1            34070        34070        \n",
      "\n",
      "France          1            34069        34069        \n",
      "\n",
      "Brittany        1            34068        34068        \n",
      "\n",
      "baseline        1            34067        34067        \n",
      "\n",
      "licence         1            34066        34066        \n",
      "\n",
      "used-car        1            34065        34065        \n",
      "\n",
      "mandate         1            34064        34064        \n",
      "\n",
      "nearly-empty    1            34063        34063        \n",
      "\n",
      "14k             1            34062        34062        \n",
      "\n",
      "practically-new 1            34061        34061        \n",
      "\n",
      "30-point        1            34060        34060        \n",
      "\n",
      "dynamics        1            34059        34059        \n",
      "\n",
      "Yakisoba        1            34058        34058        \n",
      "\n",
      "complying       1            34057        34057        \n",
      "\n",
      "susan           1            34056        34056        \n",
      "\n",
      "taiwanese/chinese 1            34055        34055        \n",
      "\n",
      "stein           1            34054        34054        \n",
      "\n",
      "f*ed            1            34053        34053        \n",
      "\n",
      "12/8/15         1            34052        34052        \n",
      "\n",
      "119             1            34051        34051        \n",
      "\n",
      "Xrays           1            34050        34050        \n",
      "\n",
      "restated        1            34049        34049        \n",
      "\n",
      "jug             1            34048        34048        \n",
      "\n",
      "childlike       1            34047        34047        \n",
      "\n",
      "highways        1            34046        34046        \n",
      "\n",
      "denotes         1            34045        34045        \n",
      "\n",
      "reason..        1            34044        34044        \n",
      "\n",
      "clipboards      1            34043        34043        \n",
      "\n",
      "classified      1            34042        34042        \n",
      "\n",
      "implicit        1            34041        34041        \n",
      "\n",
      "notarize        1            34040        34040        \n",
      "\n",
      "notarized       1            34039        34039        \n",
      "\n",
      "relating        1            34038        34038        \n",
      "\n",
      "bar/grabbing    1            34037        34037        \n",
      "\n",
      "linked          1            34036        34036        \n",
      "\n",
      "Bf              1            34035        34035        \n",
      "\n",
      "sizes/weights   1            34034        34034        \n",
      "\n",
      "bowlers         1            34033        34033        \n",
      "\n",
      "ALLEY           1            34032        34032        \n",
      "\n",
      "BOWLING         1            34031        34031        \n",
      "\n",
      "cmon            1            34030        34030        \n",
      "\n",
      "fixated         1            34029        34029        \n",
      "\n",
      ".WOW            1            34028        34028        \n",
      "\n",
      "staff/management 1            34027        34027        \n",
      "\n",
      "Jesse           1            34026        34026        \n",
      "\n",
      "semi-upscale    1            34025        34025        \n",
      "\n",
      "piccolo         1            34024        34024        \n",
      "\n",
      "34123\n"
     ]
    }
   ],
   "source": [
    "\n",
    "WORDS = compute_zipf_table(get_words(thounsand_reviews), (\"rank\", \"descending\"), num_rows=100)\n",
    "\n",
    "print(len(WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
