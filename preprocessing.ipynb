{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YELP Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from collections import Counter\n",
    "import reverse_geocoder\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Folder already exists.\nFolder already exists.\n"
    }
   ],
   "source": [
    "# DEFAULTS\n",
    "\n",
    "# define folder structure\n",
    "base_path = os.getcwd()\n",
    "data_path = base_path + '/data'\n",
    "intermediate_data_path = data_path + '/intermediate'\n",
    "\n",
    "try:\n",
    "    os.mkdir(data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(intermediate_data_path)\n",
    "    print(\"Folder created.\")\n",
    "except FileExistsError:\n",
    "    print(\"Folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MODELS\n",
    "\n",
    "# Business\n",
    "class Business:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "businesses = dict()\n",
    "\n",
    "# Review\n",
    "class Review:\n",
    "    def __init__(self, json):\n",
    "        self.__dict__ = json\n",
    "\n",
    "reviews = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 192609/192609 [00:03<00:00, 54565.49it/s]# of Businesses: 192609\n\n"
    }
   ],
   "source": [
    "# import businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_business.json', encoding=\"utf8\") as businesses_file:\n",
    "    for l in tqdm(businesses_file.readlines()):\n",
    "        b = Business(json.loads(l))\n",
    "        businesses[b.business_id] = b\n",
    "\n",
    "print(\"# of Businesses: \" + str(len(businesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading formatted geocoded file...\nIllinois: 1930\n"
    }
   ],
   "source": [
    "# Filter businesses by state.\n",
    "\n",
    "# Choose the state(s) to filter\n",
    "STATE_TO_FILTER = 'Illinois'\n",
    "\n",
    "states = dict()\n",
    "def add_or_update(state, business):\n",
    "    if state in states:\n",
    "        states[state].add(business)\n",
    "    else:\n",
    "        states[state] = set([business])\n",
    "\n",
    "business_list = list(businesses.values())\n",
    "\n",
    "# Find coordinates by using the reverse_geocoder\n",
    "coordinates = [(c.latitude, c.longitude) for c in business_list]\n",
    "res = reverse_geocoder.search(coordinates)\n",
    "ctr = 0\n",
    "for r in res:\n",
    "    state = r['admin1']\n",
    "    if state == STATE_TO_FILTER:\n",
    "        add_or_update(state, business_list[ctr])\n",
    "    ctr += 1\n",
    "\n",
    "for s in states:\n",
    "    print(s + \": \" + str(len(states[s])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# Businesses to be reviewed: 1930\n100%|██████████| 6685900/6685900 [00:54<00:00, 123482.48it/s]\n# Reviews loaded: 42316\n"
    }
   ],
   "source": [
    "# List all businesses of the given states\n",
    "business_ids = set()\n",
    "for b in states[STATE_TO_FILTER]:\n",
    "    business_ids.add(b.business_id)\n",
    "\n",
    "# Get the number of businesses to look for reviews for\n",
    "print(\"# Businesses to be reviewed: \" + str(len(business_ids)))\n",
    "\n",
    "# Load all reviews with respect to the given businesses\n",
    "with open(data_path + '/yelp/yelp_academic_dataset_review.json', encoding=\"utf8\") as reviews_file:\n",
    "    for l in tqdm(reviews_file.readlines()):\n",
    "        r = Review(json.loads(l))\n",
    "        if r.business_id in business_ids:\n",
    "            reviews[r.review_id] = r\n",
    "\n",
    "print(\"# Reviews loaded: \" + str(len(reviews.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 192609/192609 [00:00<00:00, 970411.40it/s]\n100%|██████████| 42316/42316 [00:01<00:00, 41657.88it/s]\n"
    }
   ],
   "source": [
    "businesses_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_businesses.json', 'w')\n",
    "for b in tqdm(businesses):\n",
    "    if businesses[b].business_id in business_ids:\n",
    "        json.dump(businesses[b].__dict__, businesses_intermediate_file)\n",
    "        businesses_intermediate_file.write(\"\\n\")\n",
    "businesses_intermediate_file.close()\n",
    "\n",
    "reviews_intermediate_file = open(intermediate_data_path + '/' + STATE_TO_FILTER + '_reviews.json', 'w')\n",
    "for r in tqdm(reviews):\n",
    "    json.dump(reviews[r].__dict__, reviews_intermediate_file)\n",
    "    reviews_intermediate_file.write(\"\\n\")\n",
    "reviews_intermediate_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations:\n",
    "\n",
    "* down hill -\n",
    "* great price +\n",
    "* high quality +\n",
    "* poor quality -\n",
    "* huge fan +\n",
    "\n",
    "## Indicators for negative reviews:\n",
    "* avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zipf_table(WORDS, sort_parameters=(\"rank\", \"ascending\"), num_rows=10):\n",
    "    '''\n",
    "    WORDS = list of words;\n",
    "    sort_parameters is 2 tuple: ((\"rank\" | \"frequency\" | \"frequency_times_rank\"), (\"ascending\" | \"descending\"))\n",
    "    num_rows: number of rows displayed in table\n",
    "\n",
    "    '''\n",
    "    zipf_values = [(wort, frequ, rank, frequ*rank) for rank, (wort, frequ) in enumerate(Counter(WORDS).most_common(len(WORDS)), 1)]\n",
    "     \n",
    "    if sort_parameters[0] in (\"rank\", \"frequency\", \"frequency_times_rank\") and sort_parameters[1] in (\"ascending\", \"descending\"):\n",
    "        if sort_parameters[1] == \"ascending\":\n",
    "            sorting_order = False\n",
    "        else:\n",
    "            sorting_order = True\n",
    "        if sort_parameters[0] == \"rank\":\n",
    "            zipf_values.sort(key = lambda values: values[2], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency\":\n",
    "            print(\"ja\")\n",
    "            zipf_values.sort(key = lambda values: values[1], reverse=sorting_order)\n",
    "        elif sort_parameters[0] == \"frequency_times_rank\":\n",
    "            zipf_values.sort(key = lambda values: values[3], reverse=sorting_order)\n",
    "\n",
    "        print(\"\\n\\nZipf’s law\\n\")\n",
    "        print(\"word\"+12*(\" \")+ \"frequency\" +5*(\" \") + \"rank\"+ 9*(\" \") + \"f*runtitled:Untitled-1\")\n",
    "        print(\"-----------------------------------------------\")   \n",
    "        i = 0\n",
    "        for wort, f, r, f_r in zipf_values:\n",
    "            if i < num_rows:\n",
    "                i += 1 \n",
    "                if len(str(wort))<15:\n",
    "                    wort = wort+ \" \"*(15-len(str(wort)))\n",
    "                if len(str(f))<12:\n",
    "                    f_str = str(f) + \" \"*(12-len(str(f)))\n",
    "                if len(str(r))<12:\n",
    "                    r_str = str(r) + \" \"*(12-len(str(r)))\n",
    "                if len(str(f_r))<12:\n",
    "                    f_r_str = str(f_r)+ \" \"*(12-len(str(f_r)))\n",
    "                print(wort,f_str,r_str,f_r_str, \"\\n\")   \n",
    "            else:\n",
    "                 break\n",
    "    else:\n",
    "        print(\"Invalid sorting parameter(s)!\")\n",
    "    return zipf_values\n",
    "\n",
    "def get_words(review_dict):\n",
    "    #return [word for review_obj in review_dict.values() for word in nltk.word_tokenize(review_obj.text)]\n",
    "    all_words = []\n",
    "    for review_obj in tqdm(review_dict.values()):\n",
    "        for word in nltk.word_tokenize(review_obj.text):\n",
    "            all_words.append(word)\n",
    "    return all_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "thounsand_reviews = {key:value for index, (key, value) in enumerate(reviews.items()) if index < 10000}\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORDS = compute_zipf_table(get_words(thounsand_reviews), (\"rank\", \"descending\"), num_rows=100)\n",
    "\n",
    "print(len(WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}